\documentclass[aps,11pt,twoside,letterpaper]{revtex4}


%MARK STUFF

%\documentclass[smallextended]{svjour3}%
\pdfoutput=1
\usepackage{graphics,amsmath,amsfonts,amscd,revsymb,latexsym,
enumerate,multirow,epsfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}%
\usepackage{fullpage}
\setcounter{MaxMatrixCols}{30}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2953}
%TCIDATA{LastRevised=Monday, July 20, 2009 02:05:40}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}













\usepackage{amsfonts, amssymb, amsmath, amsthm, latexsym}   %, amscd, alltt, setspace, bbm}
\usepackage{epic,eepic}
%\RequirePackage[verbose,
%                letterpaper,
%                top=3cm,
%               left=2cm,
%               right=5cm,
%                bottom=3cm,
%               ]{geometry}
%\usepackage{hyperref}


%\usepackage{graphicx}
%\usepackage{xcolor}
%\usepackage{pstricks}               % for figures
%\input{Qcircuit.tex}        % for little circuit diagrams


\renewcommand{\familydefault}{ppl}
\renewcommand{\baselinestretch}{1.0}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{header.tex}  % header with all macros and Quantum shortcuts




% CONDITIONAL COMPILATION %%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{ifthen}

% this document has two versions WITHPROOFS is
% intended for Hayden team research group -- without proofs
% is intended for the shorter project version whose page length is bounded above by 8
\newboolean{WITHPROOFS}
\setboolean{WITHPROOFS}{true} % boolvar=true or false






\begin{document}


\title{{\Large Outer bounds on the quantum interference channel} }
\date{\today} 
\author{Ivan Savov}
%     \email{}
%\affiliation{ School of Computer Science, McGill University, Montreal, Quebec, H3A 2A7, Canada }
\affiliation{ECSE 612 (multiuser communications) project, McGill University}
\keywords{interference channel, quantum Shannon theory, outer bounds}\date{\today }

%%% TODO
% 2/  copy ifdef from multipary mutual independence paper....


\begin{abstract}
    title says it all
\end{abstract}

\parskip .75ex             % spacing between paragraphs
\maketitle


\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


    The interference channel is a communication network where two transmitters try to send
    information to two receivers using a shared medium. 
    This communication scenario is one of the most general possible in multiuser information
    theory; it includes the multiple access channel (MAC) and the broadcast channel (BC)
    as special cases.
    
    The interference channel is an excellent model for many practical communication scenarios
    where medium contention is a issue. This is why obtaining an expression for the capacity region
    $\mathcal{C}$ was a central in the 70 ties and more recently.
    %
    Despite the practical importance of the problem, there are very few results about 
    discrete memoryless interference channels (DMIC) to date.
    Even the special case of Gaussian channels there the capacity region is not known.
    % only have for degraded, high interference 
    % the most important case: low / medium interference the capacity is not known...
    

    Recently, quantum information theory ...
    
    This paper will try to review classic results on the interference channel and
    define the problem in the quantum setting.
    Specifically we will try to focus on the 
    
    
    
    
 \section{Preliminaries}

        \begin{definition}[Interference network]
            A two party interference network $(\cX_1 \otimes \cX_2, p(y_1,y_2|x_1,x_2), \cY_1 \otimes \cY_2)$ 
            is general model for communication networks with two inputs, two outputs and a probability transistion
            matrix $p(y_1,y_2|x_1,x_2)$.
        \end{definition}
        
        

        \begin{definition}[Interference channel]
            A two party interference channel is a particular use of an interference network 
            $(\cX_1 \otimes \cX_2, p(y_1,y_2|x_1,x_2), \cY_1 \otimes \cY_2)$ 
            where a message $M_1$ is encoded into a codeword $X_1$ and is to be extracted at the receiver $Y_1$.
        \end{definition}

        another version -- II

        
        \begin{definition}[Achievable rate pair]
            We say that a rate $(R_1,R_2)$ is achievable for a channel $(\cX_1 \otimes \cX_2, p(y_1,y_2|x_1,x_2), \cY_1 \otimes \cY_2)$
            if there exists a code for $n$ uses of the channel where the messages taken from respective sets $\{1,2,\ldots,2^{nR_1} \}$ and
             $\{1,2,\ldots,2^{nR_2} \}$ are transmitted with vanishing error probability.
        \end{definition}
        
        
        \begin{definition}[Capacity]
            The capacity region $\cC$ of is the closure of the set of achievable rates $(R_1,R_2)$.
        \end{definition}


        \begin{definition}[Degraded channel]
            Let $Y \sim p_y(y|x_1,x_2)$ and $Z \sim p_z(z|x_1,x_2)$ be two conditional distributions.
            We say Y is a \emph{degraded version} of Z ...
            copy from \cite{Carleial83} II A.
        \end{definition}


    \subsection{Relation to multiple access and broadcast channels}

        We can think of the IC as either two multiple access channels or
        two two broadcast channels.
        
        It is therefore important to review briefly the known capacity results
        for these simpler channels.

        \paragraph{Multiple access}

            Let's say that using random coding to achieve the 
            multiple access rate $(R_1,R_2)$ to receiver Rx1.
            If you can also use random coding to acieve 
            rates $(R'_1,R'_2)$ for  multiple access communication to Rx2, 
            and if $R'_1 > R_1$ and $R'_2 > R_2$, then you can
            achieve the IC task at rate  $(R_1,R_2)$.
            
            Note however that the decomposition of the IC in terms of
            two multiple access channels is too restrictive,  since in fact
            Rx2 doesn't need to learn $M_2$ at all. 
            Sure it can be useful side informaiton, but it is not a requirement.
            
            A more direct generalization of MACs would be multiple multiple-access channels (MMAC)
            will be to require both messages $M_1$ and $M_2$ to be decodable
            at both receivers.
            The notion of interference will be then be much more interesting.
            In fact the code used for the Tx1-Rx1 communication will have to also
            be easily decodable at Rx2? Is it the same code? Surely with random
            coding it works, but what about more general inner-outer codes?
            
            I wonder if there are no relations to network coding which we can do
            at this very low level of information theory. 

            The difference between the IC and the MMAC is that we guarantee
            that an extra ressource of "cross communication" is available.
            Wouldn't it be best to represent rates then as 4-tuples?
            \be
            \left( \begin{array}{cc}
            R_{11}     &    R_{12}    \\
            R_{21}     &    R_{22}    
             \end{array} \right)
            \ee
            
            The IC problem is basically a promise about $R_{11}$ and $R_{22}$,
            and no statement about the cross rates.
            
            Are the cross rates not useful? 
            These extra rates could be used to convert some other information 
            and I feel they should be taken into account in general.
            (entanglement between receivers?)
            
            
            Another generalization that we will not be considered here is
            when the two inputs sources $X_1,X_2$ can be correlated.
            To study this problem we must also be familiar with Slepian-Wolf
            coding of correlated sources. In general the joint source-channel coding
            is a very interesting problem that remains...
            \comment{What can I say more precisely?}
            
            
        \paragraph{Broadcast}

            Both only depend on marginals $p(y_1|x_1x_2)$ and $p(y_2|x_1x_2)$ since 
            if we manage to get both decoding errors low then we manage to get the
            error of the AND of the two events also. \comment{more details needed...}

            If a rate pair is impossible for a broadcast sub
           




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Literature review}

    \subsection{Early papers}

        \cite{Ahlswede1974}
        \cite{Sato77}


    \subsection{Outer bounds}
   

    \subsection{Quantum communicaiton channels}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Known outer bounds}

        
    \subsection{Naive outer bound}
        
        Both broadcast channels and multiple access channel are special cases of the interference channel.
        In particular we can think of the interference channel as two separate multiple access channels.
        
        We know that the region defined by
        \bea \label{eqn:naive-bound}
            R_1     &\leq&    I(X_1;Y_2|X_2) \\
            R_2     &\leq&    I(X_2;Y_2|X_1)
        \eea
        contains the capacity region $\cC$.
        
        This corresponds to a very loose rectangular bound on the true capacity region.
        

        
    \subsection{Sato bound}
        
        We can describe a more precises outer bound to the capacity region by spcifying
        an inequality on the sum rate $R_1+R_2$. This was done by Sato \cite{Sato1978}.
        
        The outer bound becomes:
        \bea \label{eqn:sato-outer-bound}
            R_1             &\leq&    I(X_1;Y_2|X_2) \\
            R_2             &\leq&    I(X_2;Y_2|X_1) \\
            R_1+R_2    &\leq&    I(X_1X_2;Y_1Y_2) 
        \eea
        
        
        
        \ifthenelse {\boolean{WITHPROOFS}} 
        {
        \begin{proof}
            b
        \end{proof}
        }
        {
        \begin{proof}
            Proof available in extended version of this document.
        \end{proof}
        }



    \subsection{Carleial}

        A further development concerning an outer bound was obtained by Carleilal \cite{Carleial83}.
        
        Consider the two random variables $Z_1,Z_2$ such that 
        \bea
            Y_1 &\textrm{ is a degraded version of }& Z_1 \\
            Y_2 &\textrm{ is a degraded version of }& Z_2 \\        
            Y_2 &\textrm{ is a degraded version of }& (X_1,Z_1) \\        
            Y_1 &\textrm{ is a degraded version of }& (X_2,Z_2) 
        \eea
        
        If we think of $Z_1,Z_2$ as the outputs of the channel, we can interpret the above
        conditions as the following. 
        Knowing the input and output of the other person's communication we can recover our own signal.
        %
        If we manage to decode our message correctly, then I can also simulate the output that the other
        person has received -- i.e. I have a joint decoder on $(Y_1,Y_2)$.
        
        
        then we have the following outer bound
        \bea \label{eqn:carleial-outer-bound}
            R_1             &\leq&    I(X_1;Y_1|X_2) \\
            R_2             &\leq&    I(X_2;Y_2|X_1) \\
            R_1+R_2     &\leq&   \min\!\left\{ I(X_1X_2;Z_1), I(X_1X_2;Z_2) \right\}             
            %R_1+R_2     &\leq&   I(X_1X_2;Z_1) \\
            %R_1+R_2     &\leq&    I(X_1X_2;Z_2) 
        \eea
        
        
        
    \subsection{Nair - El Gamal outer bound}
       
        \comment{is this useful?}
        
        In a recent paper \cite{Nair2006}, Nair and El Gamal give the following outer bound on the BC
        with independent messages $M_1,M_2$ encoded into $U,V$ respectively,
        which are later \emph{jointly encoded} into an input symbol $X$ for the BC.
        
        \bea \label{eqn:nair-outer-bound}
            R_1             &\leq&    I(U;Y_1) \\
            R_2             &\leq&    I(V;Y_2) \\
            R_1+R_2     &\leq&   I(U;Y_1) + I(V;Y_2 | U) \\
            R_1+R_2     &\leq&   I(V;Y_2) + I(U;Y_1 | V) 
        \eea        
        for some choice of input distribution $p(u,v,x)=p(u,v)p(x|u,v)$. 
        
        The region defined above is an outer bound on the BC, which
        involves joint encoding of the two sources $U,V$.
        If we are dealing with the IC, we have a more restrictive scenario
        since $U \to X_1$ and $V \to X_2$, i.e. we don't have joint encoding
        of the two sources.
        
        It follows that the above region is also an outer bound on the IC cap region.
        



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quantum interference channel}


    



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

    open problems...



\appendix


\section{Introduction to QIT}

    states...

%\bibliographystyle{unsrt}
\bibliographystyle{alpha}
\bibliography{interferenceChannel}






\end{document}


